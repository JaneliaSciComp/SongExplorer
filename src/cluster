#!/usr/bin/env python3

# reduce dimensionality of internal activation states

# e.g.
# $SONGEXPLORER_BIN cluster \
#     --data_dir=`pwd`/groundtruth-data \
#     --layers=0,1,2,3,4 \
#     --pca_fraction_variance_to_retain=1 \
#     --pca_batch_size=5 \
#     --algorithm=UMAP \
#     --ndims=3 \
#     --parallelize=0 \
#     --kwargs='{"n_neighbors": 10, "min_distance": 0.1}'
 
import argparse
import os
import numpy as np
import sys
from sklearn.decomposition import PCA, IncrementalPCA
from umap import UMAP
from sklearn.manifold import TSNE
from natsort import natsorted
from datetime import datetime
import socket
from itertools import repeat

import json

def do_cluster(activations_tocluster, ilayer, layers, algorithm, ndims, kwargs):
  if algorithm=="PCA":
    return activations_tocluster[ilayer][:,:ndims]
  elif algorithm=="tSNE":
    print("reducing dimensionality with t-SNE...")
    if ilayer in layers:
      return TSNE(n_components=ndims, verbose=3, \
                        perplexity=kwargs["perplexity"], \
                        early_exaggeration=kwargs["exaggeration"] \
                       ).fit_transform(activations_tocluster[ilayer])
    else:
      return None
  elif algorithm=="UMAP":
    print("reducing dimensionality with UMAP...")
    if ilayer in layers:
      return UMAP(n_components=ndims, verbose=3, \
                  n_neighbors=kwargs["n_neighbors"], \
                  min_dist=kwargs["min_distance"] \
                 ).fit_transform(activations_tocluster[ilayer])
    else:
      return None

FLAGS = None

def main():
  flags = vars(FLAGS)
  for key in sorted(flags.keys()):
    print('%s = %s' % (key, flags[key]))

  layers = [int(x) for x in FLAGS.layers.split(',')]

  if FLAGS.algorithm not in ["PCA", "tSNE", "UMAP"]:
    print('cluster_algorithm must be one of PCA, tSNE or UMAP')
    exit()

  print("loading data...")
  activations=[]
  npzfile = np.load(os.path.join(FLAGS.data_dir, 'activations.npz'),
                    allow_pickle=True)
  sounds = npzfile['sounds']
  for arr_ in natsorted(filter(lambda x: x.startswith('arr_'), npzfile.files)):
    activations.append(npzfile[arr_])

  nlayers = len(activations)

  kinds = set([x['kind'] for x in sounds])
  labels = set([x['label'] for x in sounds])
  print('label counts')
  for kind in kinds:
    print(kind)
    for label in labels:
      count = sum([label==x['label'] and kind==x['kind'] for x in sounds])
      print(count,label)


  activations_flattened = [None]*nlayers
  for ilayer in range(nlayers):
    if ilayer not in layers:
      continue
    nsounds = np.shape(activations[ilayer])[0]
    activations_flattened[ilayer] = np.reshape(activations[ilayer],(nsounds,-1))
    print(np.shape(activations_flattened[ilayer]))


  fits_pca = [None]*nlayers
  if FLAGS.pca_fraction_variance_to_retain<1 or FLAGS.algorithm=="PCA":
    print("reducing dimensionality with PCA...")

    activations_scaled = [None]*nlayers
    for ilayer in range(nlayers):
      if ilayer not in layers:
        continue
      mu = np.mean(activations_flattened[ilayer], axis=0)
      sigma = np.std(activations_flattened[ilayer], axis=0)
      activations_scaled[ilayer] = (activations_flattened[ilayer]-mu)/sigma
      if FLAGS.pca_batch_size==0:
        pca = PCA()
      else:
        nfeatures = np.shape(activations_scaled[ilayer])[1]
        pca = IncrementalPCA(batch_size=FLAGS.pca_batch_size*nfeatures)
      fits_pca[ilayer] =  pca.fit(activations_scaled[ilayer])
      print(np.shape(fits_pca[ilayer]))

    import matplotlib as mpl
    mpl.use('Agg')
    import matplotlib.pyplot as plt
    #plt.ion()

    activations_kept = [None]*nlayers
    fig = plt.figure()
    ax = fig.add_subplot(111)
    for ilayer in range(nlayers):
      if ilayer not in layers:
        continue
      cumsum = np.cumsum(fits_pca[ilayer].explained_variance_ratio_)
      ncomponents = np.where(cumsum>=FLAGS.pca_fraction_variance_to_retain)[0][0]
      line, = ax.plot(cumsum)
      activations_transformed = fits_pca[ilayer].transform(activations_scaled[ilayer])
      if FLAGS.algorithm=="PCA":
        line.set_label('layer '+str(ilayer)+', n='+str(np.shape(activations_transformed)[1]))
        activations_kept[ilayer] = activations_transformed
      else:
        line.set_label('layer '+str(ilayer)+', n='+str(ncomponents+1))
        activations_kept[ilayer] = activations_transformed[:,0:ncomponents+1]

    ax.set_ylabel('cumsum explained variance')
    ax.set_xlabel('# of components')
    ax.legend(loc='lower right')
    plt.savefig(os.path.join(FLAGS.data_dir, 'cluster-pca.pdf'))

    activations_tocluster = activations_kept
  else:
    activations_tocluster = activations_flattened

  if FLAGS.parallelize!=0:
    from multiprocessing import Pool
    nprocs = os.cpu_count() if FLAGS.parallelize==-1 else FLAGS.parallelize
    with Pool(min(nprocs,nlayers)) as p:
      activations_clustered = p.starmap(do_cluster,
                                        zip(repeat(activations_tocluster),
                                            range(len(activations_tocluster)),
                                            repeat(layers),
                                            repeat(FLAGS.algorithm),
                                            repeat(FLAGS.ndims),
                                            repeat(FLAGS.kwargs)))
  else:
    activations_clustered = [None]*nlayers
    for ilayer in layers:
      print('layer '+str(ilayer))
      activations_clustered[ilayer] = do_cluster(activations_tocluster, \
                                                 ilayer, \
                                                 layers, \
                                                 FLAGS.algorithm, \
                                                 FLAGS.ndims, \
                                                 FLAGS.kwargs)

  np.savez(os.path.join(FLAGS.data_dir, 'cluster'), \
           sounds=sounds,
           activations_clustered=activations_clustered,
           fits_pca=fits_pca)
  
if __name__ == "__main__":
  parser = argparse.ArgumentParser()
  parser.add_argument(
      '--data_dir',
      type=str)
  parser.add_argument(
      '--layers',
      type=str)
  parser.add_argument(
      '--pca_fraction_variance_to_retain',
      type=float)
  parser.add_argument(
      '--pca_batch_size',
      type=int)
  parser.add_argument(
      '--algorithm',
      type=str,
      default='UMAP')
  parser.add_argument(
      '--ndims',
      type=int,
      default=2)
  parser.add_argument(
      '--parallelize',
      type=int,
      default=0)
  parser.add_argument(
      '--kwargs',
      type=json.loads,
      default='{"n_neighbors": 10, "min_distance": 0.1}')

  FLAGS, unparsed = parser.parse_known_args()

  print(str(datetime.now())+": start time")
  repodir = os.path.dirname(os.path.dirname(os.path.realpath(__file__)))
  with open(os.path.join(repodir, "VERSION.txt"), 'r') as fid:
    print('SongExplorer version = '+fid.read().strip().replace('\n',', '))
  print("hostname = "+socket.gethostname())
  
  try:
    main()

  except Exception as e:
    print(e)
  
  finally:
    if hasattr(os, 'sync'):
      os.sync()
    print(str(datetime.now())+": finish time")
